# MLP
This repo contains a full implementation of a fully extensible multilayer perceptron. The problem is formulated as a series of matrix multiplication using numpy only.

# MNIST
MNIST is a standard benchmark for neural networks. With our simple implementation we get good results on this dataset.

# Handwritten digit classification
After training our network, we use user input to classify test example. In this case the classification is live & interactive
![Image 1](/docs/3.png?raw=true "Prediction:3")
![Image 2](/docs/4.png?raw=true "Prediction:4")
![Image 3](/docs/8.png?raw=true "Prediction:8")
![Image 4](/docs/misclassification.png?raw=true "Misclassification")
## About: MLP NN
Our multilayer perceptron uses two hidden layers with 100 units each.

## Special Thanks:
Brian Dolhansky: His tutorials gave me great understanding of backpropagation algorithm
Siraj Raval: The live classification was inspired from one of his tutorials
